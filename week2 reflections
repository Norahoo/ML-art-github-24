7/18
//Reflect on the relationship between labels and images in a machine learning image classification dataset. 
Who has the power to label images and how do those labels and machine learning models trained on them impact society?


After reading Excavating AI, I find it’s interesting to see how the use of technology is affected by humans. 
Since AI is trained by vast amount of data sets, the choice of data sets and how they are being categorized 
is not something that could be learned by AI itself. As researchers and scientists have the power to teach AI
how to label images, their decisions and actions are actually influenced by the social ideology. While some 
topics are already controversial in the society, people are also affected by this ambiguity and further lead 
to unfairness shown by AI. For example, while researching in categorizing humans, AI and the behind team tend 
to use physiognomy to label a person. That ambiguity causes a terrible show of bias. Such as beautiful girls 
are labeled as ball-busters, and there are different looks for assistant professor and professor. Actually 
there are many space for the explanation, and people won’t change their look for being promoted in their positions. 
All the examples seem unprofessional and biased, which are not accepted by us. So while AI is really being devoted 
to product, the bias could be aggravated. Since some people don’t really know how to classify, they might consider
AI as standard, which could cause bid trouble for the society fairness.
